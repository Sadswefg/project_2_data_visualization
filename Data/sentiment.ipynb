{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "file_path = 'merged_reddit_tourism_headlines.csv'  # Update the path as needed\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    City                                           Headline  \\\n",
      "0  Hanoi  Saigon or Hanoi, which city has tourism more d...   \n",
      "1  Hanoi                  Hanoi to develop heritage tourism   \n",
      "2  Hanoi     Hanoi moves to optimise golf tourism potential   \n",
      "3  Hanoi    Hanoi Tourism | Do papers desire 3 figure lines   \n",
      "4  Hanoi  HCM City, Hanoi earn highest revenue from tourism   \n",
      "\n",
      "                  Date                                          sentiment  \\\n",
      "0  2023-09-13 16:03:51  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   \n",
      "1  2023-05-26 06:40:21  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   \n",
      "2  2023-05-26 20:58:10  {'neg': 0.0, 'neu': 0.674, 'pos': 0.326, 'comp...   \n",
      "3  2022-11-11 17:28:22  {'neg': 0.0, 'neu': 0.748, 'pos': 0.252, 'comp...   \n",
      "4  2022-08-11 11:15:08  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   \n",
      "\n",
      "   compound  positive  neutral  negative  \n",
      "0    0.0000     0.000    1.000       0.0  \n",
      "1    0.0000     0.000    1.000       0.0  \n",
      "2    0.4404     0.326    0.674       0.0  \n",
      "3    0.4019     0.252    0.748       0.0  \n",
      "4    0.0000     0.000    1.000       0.0  \n"
     ]
    }
   ],
   "source": [
    "def analyze_sentiment(text):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    return scores\n",
    "\n",
    "# Apply sentiment analysis to the data\n",
    "data['sentiment'] = data['Headline'].apply(analyze_sentiment)\n",
    "\n",
    "# Extract sentiment scores into separate columns\n",
    "data['compound'] = data['sentiment'].apply(lambda x: x['compound'])\n",
    "data['positive'] = data['sentiment'].apply(lambda x: x['pos'])\n",
    "data['neutral'] = data['sentiment'].apply(lambda x: x['neu'])\n",
    "data['negative'] = data['sentiment'].apply(lambda x: x['neg'])\n",
    "\n",
    "# Show the first few rows of the dataframe\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = 'reddit_tourism_headlines_with_sentiment.csv'  # Update the path as needed\n",
    "data.to_csv(output_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
